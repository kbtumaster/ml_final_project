{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "r_YlednZxY6O"
   },
   "outputs": [],
   "source": [
    "import requests as re\n",
    "import uri\n",
    "import telebot\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import urllib.request as urllib2\n",
    "import cv2\n",
    "import pytesseract\n",
    "import logging\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_message_text = \"Hi! This is a bot made for the final ML project.\\nTeam members: Suleimen Daukishov, Nurmukhammed Abeuov, Asylkhan Otegaliev. \\nJust send the bot a photo and it will send you the text on it!\"\n",
    "BOT_TOKEN = 'BOT_TOKEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img, title=\"\"):\n",
    "    plt.title(title)\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_images(imgs):\n",
    "    imgs.reverse()\n",
    "    plt.figure(figsize=(7, 15)) # specifying the overall grid size\n",
    "    for i, img in enumerate(imgs):\n",
    "        plt.subplot(3, len(imgs), i + 1)    # the number of images in the grid is 5*5 (25)\n",
    "        plt.title(img[1])\n",
    "        plt.imshow(img[0])\n",
    "    plt.show()\n",
    "    \n",
    "def resize_img(img, basewidth):\n",
    "    print(img)\n",
    "    wpercent = (basewidth / float(img.size[0]))\n",
    "    hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "    img = img.resize((basewidth, hsize), Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "def not_correct(pixel_array, percent):\n",
    "    pixel_array = pixel_array.flatten()\n",
    "    white_pixs = [x for x in pixel_array if x == 255]\n",
    "    \n",
    "    true_percent = len(white_pixs) / len(pixel_array) * 100\n",
    "    \n",
    "    if true_percent > percent:\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def delete_punct(img):\n",
    "    h, w = img.size\n",
    "    if h < 14 and w < 14:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_concat_h(im1, im2):\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "def get_concat_v(im1, im2):\n",
    "    basewidth = im2.size[0]\n",
    "    wpercent = (basewidth/float(im1.size[0]))\n",
    "    im1 = im1.resize((basewidth, im1.size[1]), Image.ANTIALIAS)\n",
    "    dst = Image.new('RGB', (im2.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "def split_word_to_letter(path, letter_padding=1):\n",
    "    img = path\n",
    "\n",
    "    im = cv2.imread(img,0)\n",
    "    pil_img = Image.open(img)\n",
    "    hlimg, wlimg = im.shape[0], im.shape[1]\n",
    "\n",
    "    ret,thresh1 = cv2.threshold(im, 127, 100, cv2.THRESH_BINARY)\n",
    "    contours, hierarchy = cv2.findContours(thresh1,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     show_image(im)\n",
    "\n",
    "    image_data = pytesseract.image_to_boxes(im, output_type=pytesseract.Output.DICT, lang=\"kaz\")\n",
    "    image_data['char'] = [x.lower() for x in image_data['char']]\n",
    "\n",
    "    # COUNT I LETTER TO EARLY STOP\n",
    "    count_i = image_data['char'].count('й')\n",
    "\n",
    "    # let_indeсes = [n for n,x in enumerate(image_data['char']) if x.lower()=='й']\n",
    "    # for let_index in let_indeсes:\n",
    "    #     image_data['char'].insert(let_index+1, 'й')\n",
    "\n",
    "\n",
    "    # DOUBLE ы\n",
    "    let_indeсes = [n for n,x in enumerate(image_data['char']) if x.lower()=='ы']\n",
    "    for let_index in let_indeсes:\n",
    "        image_data['char'].insert(let_index+1, 'ы')\n",
    "\n",
    "    letters_count = len(image_data['char'])\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    letter_idx = 0\n",
    "\n",
    "    merge_list = []\n",
    "    result = []\n",
    "    x, y, w, h = cv2.boundingRect(contours[-1])\n",
    "    i_hat = pil_img.crop((x - letter_padding, y - letter_padding, x+w + letter_padding, y+h + letter_padding))\n",
    "\n",
    "\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "    #     print(x, y, w, h)\n",
    "        # BOUND IMAGES\n",
    "        img_croped_letters = pil_img.crop((x - 1, y - 1, x+w + 1, y+h + 1))\n",
    "\n",
    "        # CHECK CORRECT IMAGES\n",
    "        if not_correct(np.asarray(img_croped_letters)[-1], 10):\n",
    "            continue\n",
    "\n",
    "        # DELETE PUNCTUATIONS\n",
    "        if delete_punct(img_croped_letters):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "        # MERGE Ы\n",
    "            if image_data['char'][-i-1] == 'ы':\n",
    "                merge_list.append(img_croped_letters)\n",
    "                if len(merge_list) == 2:\n",
    "                    img_croped_letters = get_concat_h(merge_list[1], merge_list[0])\n",
    "                    merge_list = []\n",
    "\n",
    "        # MERGE Й\n",
    "            if image_data['char'][-i-1] == 'й':\n",
    "                img_croped_letters = get_concat_v(i_hat, img_croped_letters)\n",
    "\n",
    "        except:\n",
    "            break\n",
    "\n",
    "        i = i + 1\n",
    "        if len(merge_list) == 1:\n",
    "            continue\n",
    "\n",
    "        letter_idx = letter_idx + 1\n",
    "        if letter_idx - 1 == letters_count:\n",
    "            break\n",
    "            \n",
    "        result.append([img_croped_letters, image_data['char'][-i]])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_photo(file_path):\n",
    "    # SCRIPT\n",
    "    path_image = file_path # IMG PATH\n",
    "\n",
    "    word_padding = 5 # WORD PADDING IN PIXELS\n",
    "    letter_padding = 1 # LETTER PADDING IN PIXELS\n",
    "\n",
    "    # OPEN IMAGE \n",
    "    img = Image.open(path_image)\n",
    "    show_image(img, \"Original image\")\n",
    "\n",
    "    # GRAYSCALE\n",
    "    img = img.convert('L')\n",
    "    show_image(img, \"Gray scaled image\")\n",
    "\n",
    "    # GET IMAGE DATA\n",
    "    image_data = pytesseract.image_to_data(img, output_type=pytesseract.Output.DICT, lang=\"kaz\")\n",
    "\n",
    "    # WORD BOXES\n",
    "    k = 0\n",
    "    result = []\n",
    "    for i, word in enumerate(image_data['text']):\n",
    "        if word != \"\":\n",
    "\n",
    "            k = k + 1\n",
    "\n",
    "            # GET WORD BORDERS\n",
    "            (left, top, right, bottom) = image_data['left'][i], image_data['top'][i], image_data['left'][i] + image_data['width'][i], image_data['top'][i] + image_data['height'][i]\n",
    "\n",
    "            # CROP WORDS\n",
    "            img_croped_word = img.crop((left - word_padding, top - word_padding, right + word_padding, bottom + word_padding))\n",
    "\n",
    "            # SAVE IMAGE WORD\n",
    "            result.append(img_croped_word)\n",
    "            try:\n",
    "                res = split_word_to_letter(\"temp.jpg\", letter_padding)\n",
    "                plot_images(res)\n",
    "            except:\n",
    "                continue\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import load_model\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "model2.load_weights('weights_Kazakh_letters_VGG16_CapsNets.h5')\n",
    "labels = json.load('labels.json')\n",
    "\n",
    "def detect_text(images):\n",
    "    image_array = cv2.imread(os.listdir(images))\n",
    "    out_value = model2.predict(image_array)\n",
    "    text_output = labels[out_value]\n",
    "    text = [labels[out_value] for out_value in text_output]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wWkyRCo-xp09"
   },
   "outputs": [],
   "source": [
    "bot = telebot.TeleBot(BOT_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3MtEQfji0ftP"
   },
   "outputs": [],
   "source": [
    "def processPhotoMessage(message):\n",
    "    fileID = message.photo[-1].file_id\n",
    "    file = bot.get_file(fileID)\n",
    "    print(file)\n",
    "    image_url = 'https://api.telegram.org/file/bot{}/{}'.format(BOT_TOKEN, file.file_path)\n",
    "    download_image(image_url, file.file_path)\n",
    "    text = detect_text(file.file_path)\n",
    "    preprocessed_images = preprocess_photo(file.file_path)\n",
    "    text = detect_text(preprocessed_images)\n",
    "    print (text)\n",
    "    return text\n",
    "\n",
    "def download_image(image_url, file_path):\n",
    "    datatowrite = urllib2.urlopen(image_url).read()\n",
    "    Path(os.path.dirname(file_path)).mkdir(parents=True, exist_ok=True)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(datatowrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JKkNPL5g0tGy"
   },
   "outputs": [],
   "source": [
    "@bot.message_handler(content_types=['photo'])\n",
    "def repeat_all_messages(message): # Название функции не играет никакой роли, в принципе\n",
    "    text = processPhotoMessage(message)\n",
    "    bot.send_message(message.chat.id, text)\n",
    "\n",
    "@bot.message_handler(content_types=['text'])\n",
    "def send_message(message):\n",
    "    bot.send_message(message.chat.id, start_message_text)\n",
    "\n",
    "@bot.message_handler(commands=['start', 'help'])\n",
    "def send_message(message):\n",
    "\tbot.send_message(message.chat.id, start_message_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgQr2jm6ms_G",
    "outputId": "fbf66c08-b8cb-4d7b-d3ce-98066dbb827d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_id': 'AgACAgIAAxkBAANfYKi9VcMjjgfFu1Kw1cQDJA2nQAADSrYxGzvBQUmCqqLPhp0nG3RxF5suAAMBAAMCAAN4AAMWJAYAAR8E', 'file_unique_id': 'AQADdHEXmy4AAxYkBgAB', 'file_size': 21344, 'file_path': 'photos/file_6.jpg'}\n",
      "Texts:\n",
      "\n",
      "\"1. Бірінші Сөз\n",
      "Бұл жасқа келгенше жаксы өткіздік не, жаман өткілік не, әйтеуір бірталай\n",
      "омірімізді өткізік: алыстык, жұлыстык, айтыстык, тартыстық әурешілікті,\n",
      "коре-коре келдік. Енді жер ортасы жасқа келдік: калжыдык, жалыктык кылып\n",
      "жүрген ісіміздің бәрінін баянқызын, багілиусыгын көрдік, бәрі қоршылық\n",
      "екенін білдік. Ал, енді қалған өмірімізді қайтіп, не кылып откіземіз? Соны таба\n",
      "алмаt еім де кайранмын.\n",
      "Ел бағу? Жок, елге бағым жок. Баг усыз дертке ұшырайын деген кісі\n",
      "бактаса, не абарткан, косілі басылмаған жастар бағамын демесе, білі Құлаii\n",
      "сақтасын!\n",
      "Мал балу? Жок, бага алмаймын. Балалар еклеріне керегінне веруі балар,\n",
      "Енді картаа анда кылагын озілі түгел қоре алмайтұғын, ұры, залам,\n",
      "тілімсектердің азыгын багын беремін деп, калган аз ғана емiрiмдi кор кылар\n",
      "жайым жос.\n",
      "Гылым багу? Жок, галым бдг арга да ғылым сөзін сөйлесер адам жок.\n",
      "Білгеніңді кімге үйретесін, білмегенінді кімнен сұрайслание? Елсіз-күнсізде\n",
      "\"\n",
      "\n",
      "1. Бірінші Сөз\n",
      "Бұл жасқа келгенше жаксы өткіздік не, жаман өткілік не, әйтеуір бірталай\n",
      "омірімізді өткізік: алыстык, жұлыстык, айтыстык, тартыстық әурешілікті,\n",
      "коре-коре келдік. Енді жер ортасы жасқа келдік: калжыдык, жалыктык кылып\n",
      "жүрген ісіміздің бәрінін баянқызын, багілиусыгын көрдік, бәрі қоршылық\n",
      "екенін білдік. Ал, енді қалған өмірімізді қайтіп, не кылып откіземіз? Соны таба\n",
      "алмаt еім де кайранмын.\n",
      "Ел бағу? Жок, елге бағым жок. Баг усыз дертке ұшырайын деген кісі\n",
      "бактаса, не абарткан, косілі басылмаған жастар бағамын демесе, білі Құлаii\n",
      "сақтасын!\n",
      "Мал балу? Жок, бага алмаймын. Балалар еклеріне керегінне веруі балар,\n",
      "Енді картаа анда кылагын озілі түгел қоре алмайтұғын, ұры, залам,\n",
      "тілімсектердің азыгын багын беремін деп, калган аз ғана емiрiмдi кор кылар\n",
      "жайым жос.\n",
      "Гылым багу? Жок, галым бдг арга да ғылым сөзін сөйлесер адам жок.\n",
      "Білгеніңді кімге үйретесін, білмегенінді кімнен сұрайслание? Елсіз-күнсізде\n",
      "\n",
      "{'file_id': 'AgACAgIAAxkBAANhYKjAaZG56KFznGGZUEc4BOiAkjcAAk22MRs7wUFJtqPKIRS4AAGk4GNVoi4AAwEAAwIAA3gAA9ttAgABHwQ', 'file_unique_id': 'AQAD4GNVoi4AA9ttAgAB', 'file_size': 30421, 'file_path': 'photos/file_7.jpg'}\n",
      "Texts:\n",
      "\n",
      "\"38. Отыз Сегізінші Сөз\n",
      "Ей, жүрегімнің қуаты, перзенттерім! Сіздерге адам ұғымының мінездері\n",
      "тұғралы біраз сөз жазып ядкар\" калдырайын. Ықылас бірлэн окып, ұғып\n",
      "алыңыздар, анын үшін махаббатың толады. Махаббат — әуел адамның\n",
      "адамдығы, ғақыл, ғылым деген нәрселер бірлән. Мұның табылмактығына\n",
      "себептер әуелі һауас сәлим\" һәм тән саулык, бұлар туысынан болады,\n",
      "калмысы жақсы ата, жақсы ана, жақсы құрбы, жақсы ұстаздан болады, Талап,\n",
      "ұғым махаббаттан шығады. Ғылым-білімге махаббаттандырмақ әлгі айтылған\n",
      "үшеуінен болады.\n",
      "Ғылым-білімді әуелі бастан бала өзі ізденіп таппайды. Басында зорлықпен\n",
      "яки алдауменен үйір қылу керек, үйрене келе өзі іздегендей болғанша, Қашан\n",
      "бір бала ғылым, білімді махаббатпенен кексерулік болса, сонда ғана оның аты\n",
      "адам болады. Сонан соң ғана Алла Тағаланы танымақтық өзің танымактык,\n",
      "дүниені танымактык, у адамдығын бұзбай ғана жəліб манфағат\" даргын\n",
      "мұзирратларны\" айырмаклық секілді ғылым-білімді үйренсе, білсе деп үміт\n",
      "кылмаққа болады. Болмаса жок, ең болмаса нала. Анын үшін көбінесе\n",
      "\"\n",
      "\n",
      "38. Отыз Сегізінші Сөз\n",
      "Ей, жүрегімнің қуаты, перзенттерім! Сіздерге адам ұғымының мінездері\n",
      "тұғралы біраз сөз жазып ядкар\" калдырайын. Ықылас бірлэн окып, ұғып\n",
      "алыңыздар, анын үшін махаббатың толады. Махаббат — әуел адамның\n",
      "адамдығы, ғақыл, ғылым деген нәрселер бірлән. Мұның табылмактығына\n",
      "себептер әуелі һауас сәлим\" һәм тән саулык, бұлар туысынан болады,\n",
      "калмысы жақсы ата, жақсы ана, жақсы құрбы, жақсы ұстаздан болады, Талап,\n",
      "ұғым махаббаттан шығады. Ғылым-білімге махаббаттандырмақ әлгі айтылған\n",
      "үшеуінен болады.\n",
      "Ғылым-білімді әуелі бастан бала өзі ізденіп таппайды. Басында зорлықпен\n",
      "яки алдауменен үйір қылу керек, үйрене келе өзі іздегендей болғанша, Қашан\n",
      "бір бала ғылым, білімді махаббатпенен кексерулік болса, сонда ғана оның аты\n",
      "адам болады. Сонан соң ғана Алла Тағаланы танымақтық өзің танымактык,\n",
      "дүниені танымактык, у адамдығын бұзбай ғана жəліб манфағат\" даргын\n",
      "мұзирратларны\" айырмаклық секілді ғылым-білімді үйренсе, білсе деп үміт\n",
      "кылмаққа болады. Болмаса жок, ең болмаса нала. Анын үшін көбінесе\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bot.polling(none_stop=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ocr_bot.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
